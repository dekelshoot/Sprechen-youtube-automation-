{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t >> load model...\n",
      " > tts_models/fr/css10/vits is already downloaded.\n",
      " > Using model: vits\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:0\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:None\n",
      " | > fft_size:1024\n",
      " | > power:None\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:None\n",
      " | > signal_norm:None\n",
      " | > symmetric_norm:None\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:None\n",
      " | > pitch_fmax:None\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > initialization of speaker-embedding layers.\n",
      " > initialization of language-embedding layers.\n",
      " > tts_models/de/css10/vits-neon is already downloaded.\n",
      " > Using model: vits\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:0\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:None\n",
      " | > fft_size:1024\n",
      " | > power:None\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:None\n",
      " | > signal_norm:None\n",
      " | > symmetric_norm:None\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:None\n",
      " | > pitch_fmax:None\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > initialization of speaker-embedding layers.\n",
      " > initialization of language-embedding layers.\n",
      "\n",
      "\t >> load data...\n",
      "\n",
      "création du dictionnaire...\n",
      "\n",
      "\t >> generate composition with data\n",
      "\n",
      "\u001b[93m0% [----------------------------]\u001b[0m\n",
      "getting voice ...\n",
      "['Ma Famille']\n",
      " > Processing time: 1.4525024890899658\n",
      " > Real-time factor: 1.2502998081056271\n",
      "voice genered ...\n",
      "playing audio ...\n",
      "\u001b[93m0% [----------------------------]\u001b[0mgetting voice ...\n",
      "['Lektion zwei : Meine Familie']\n",
      " > Processing time: 6.1482555866241455\n",
      " > Real-time factor: 2.224485358444841\n",
      "voice genered ...\n",
      "playing audio ...\n",
      "\u001b[93m0% [----------------------------]\u001b[0mdéfinition du format...\n",
      "création du background ...\n",
      "insertion du texte ...\n",
      "Composition de la vidéo ...\n",
      "Composition de l'audio ...\n",
      "\u001b[93m3% [##--------------------------]\u001b[0mgetting voice ...\n",
      "['Famille']\n",
      " > Processing time: 0.5924971103668213\n",
      " > Real-time factor: 0.40164047231887634\n",
      "voice genered ...\n",
      "playing audio ...\n",
      "\u001b[93m3% [##--------------------------]\u001b[0mgetting voice ...\n",
      "['Familie']\n",
      " > Processing time: 2.2591280937194824\n",
      " > Real-time factor: 0.5286739521407984\n",
      "voice genered ...\n",
      "playing audio ...\n",
      "\u001b[93m3% [##--------------------------]\u001b[0mdéfinition du format...\n",
      "création du background ...\n",
      "insertion du texte ...\n",
      "Composition de la vidéo ...\n",
      "Composition de l'audio ...\n",
      "\u001b[93m7% [###-------------------------]\u001b[0mgetting voice ...\n",
      "['mon']\n",
      " > Processing time: 2.3454651832580566\n",
      " > Real-time factor: 1.42206080320172\n",
      "voice genered ...\n",
      "playing audio ...\n",
      "\u001b[93m7% [###-------------------------]\u001b[0mgetting voice ...\n",
      "['mein']\n",
      " > Processing time: 6.456385612487793\n",
      " > Real-time factor: 1.5233190245180173\n",
      "voice genered ...\n",
      "playing audio ...\n",
      "\u001b[93m7% [###-------------------------]\u001b[0mdéfinition du format...\n",
      "création du background ...\n",
      "insertion du texte ...\n",
      "Composition de la vidéo ...\n",
      "Composition de l'audio ...\n",
      "\u001b[93m11% [####------------------------]\u001b[0mgetting voice ...\n",
      "['le père']\n",
      " > Processing time: 3.7819418907165527\n",
      " > Real-time factor: 2.9068536911008085\n",
      "voice genered ...\n",
      "playing audio ...\n",
      "\u001b[93m11% [####------------------------]\u001b[0mgetting voice ...\n",
      "['der Vater']\n",
      " > Processing time: 1.169191837310791\n",
      " > Real-time factor: 0.6101069673585513\n",
      "voice genered ...\n",
      "playing audio ...\n",
      "\u001b[93m11% [####------------------------]\u001b[0mdéfinition du format...\n",
      "création du background ...\n",
      "insertion du texte ...\n",
      "Composition de la vidéo ...\n",
      "Composition de l'audio ...\n",
      "\u001b[93m14% [#####-----------------------]\u001b[0mgetting voice ...\n",
      "['le frère']\n",
      " > Processing time: 0.818058967590332\n",
      " > Real-time factor: 0.7112854982400166\n",
      "voice genered ...\n",
      "playing audio ...\n",
      "\u001b[93m14% [#####-----------------------]\u001b[0mgetting voice ...\n",
      "['der Bruder']\n",
      " > Processing time: 3.8863277435302734\n",
      " > Real-time factor: 2.307559423331606\n",
      "voice genered ...\n",
      "playing audio ...\n",
      "\u001b[93m14% [#####-----------------------]\u001b[0mdéfinition du format...\n",
      "création du background ...\n",
      "insertion du texte ...\n",
      "Composition de la vidéo ...\n",
      "Composition de l'audio ...\n",
      "\u001b[93m18% [######----------------------]\u001b[0mgetting voice ...\n",
      "['le fils']\n",
      " > Processing time: 0.9343371391296387\n",
      " > Real-time factor: 0.7378987792911366\n",
      "voice genered ...\n",
      "playing audio ...\n",
      "\u001b[93m18% [######----------------------]\u001b[0mgetting voice ...\n",
      "['der Sohn']\n",
      " > Processing time: 0.9309980869293213\n",
      " > Real-time factor: 0.6678978337061274\n",
      "voice genered ...\n",
      "playing audio ...\n",
      "\u001b[93m18% [######----------------------]\u001b[0mdéfinition du format...\n",
      "création du background ...\n",
      "insertion du texte ...\n",
      "Composition de la vidéo ...\n",
      "Composition de l'audio ...\n",
      "\u001b[93m22% [#######---------------------]\u001b[0mgetting voice ...\n",
      "['le mari']\n",
      " > Processing time: 0.5488872528076172\n",
      " > Real-time factor: 0.39377160087220064\n",
      "voice genered ...\n",
      "playing audio ...\n",
      "\u001b[93m22% [#######---------------------]\u001b[0mgetting voice ...\n",
      "['der Mann']\n",
      " > Processing time: 6.740986585617065\n",
      " > Real-time factor: 2.1822697059674696\n",
      "voice genered ...\n",
      "playing audio ...\n",
      "\u001b[93m22% [#######---------------------]\u001b[0mdéfinition du format...\n",
      "création du background ...\n",
      "insertion du texte ...\n",
      "Composition de la vidéo ...\n",
      "Composition de l'audio ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/dekelshoot/Bureau/images numérique/classes/Clip.ipynb Cell 1\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dekelshoot/Bureau/images%20num%C3%A9rique/classes/Clip.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mSprechen\u001b[39;00m \u001b[39mimport\u001b[39;00m Sprechen\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/dekelshoot/Bureau/images%20num%C3%A9rique/classes/Clip.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m Sprechen(data_path\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m../data/lektion2.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/Bureau/images numérique/classes/Sprechen.py:23\u001b[0m, in \u001b[0;36mSprechen.__init__\u001b[0;34m(self, data_path, format, filename)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mload_data(data_path)\n\u001b[1;32m     22\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m >> generate composition with data\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_composition_with_data(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata)\n\u001b[1;32m     25\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m >> saving composition...\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave(filename\u001b[39m=\u001b[39mfilename)\n",
      "File \u001b[0;32m~/Bureau/images numérique/classes/Sprechen.py:65\u001b[0m, in \u001b[0;36mSprechen.generate_composition_with_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maudio_de\u001b[39m.\u001b[39mgenerate_audio(\n\u001b[1;32m     63\u001b[0m     text\u001b[39m=\u001b[39mdata[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m][key][\u001b[39m\"\u001b[39m\u001b[39mtraduction\u001b[39m\u001b[39m\"\u001b[39m], file_path\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m../temp/audio2.wav\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     64\u001b[0m sys\u001b[39m.\u001b[39mstdout\u001b[39m.\u001b[39mwrite(\u001b[39m'\u001b[39m\u001b[39m\\r\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mc)\n\u001b[0;32m---> 65\u001b[0m cl \u001b[39m=\u001b[39m Leaf_clip(bg\u001b[39m=\u001b[39;49mchoice(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_bg()), \u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mformat,\n\u001b[1;32m     66\u001b[0m                text\u001b[39m=\u001b[39;49mdata[\u001b[39m\"\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\"\u001b[39;49m][key][\u001b[39m\"\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m\"\u001b[39;49m], traduction\u001b[39m=\u001b[39;49mdata[\u001b[39m\"\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m\"\u001b[39;49m][key][\u001b[39m\"\u001b[39;49m\u001b[39mtraduction\u001b[39;49m\u001b[39m\"\u001b[39;49m], audio1\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m../temp/audio1.wav\u001b[39;49m\u001b[39m\"\u001b[39;49m, audio2\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m../temp/audio2.wav\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     67\u001b[0m sys\u001b[39m.\u001b[39mstdout\u001b[39m.\u001b[39mwrite(\u001b[39m'\u001b[39m\u001b[39m\\r\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mc)\n\u001b[1;32m     68\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcomposition\u001b[39m.\u001b[39madd_clip(cl\u001b[39m.\u001b[39mvideo)\n",
      "File \u001b[0;32m~/Bureau/images numérique/classes/Clip.py:79\u001b[0m, in \u001b[0;36mLeaf_clip.__init__\u001b[0;34m(self, bg, format, text, traduction, font, audio1, audio2)\u001b[0m\n\u001b[1;32m     75\u001b[0m audio_compo \u001b[39m=\u001b[39m CompositeAudioClip([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maudio1\u001b[39m.\u001b[39mset_start(\u001b[39m1\u001b[39m),\n\u001b[1;32m     76\u001b[0m                                   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maudio2\u001b[39m.\u001b[39mset_start(\u001b[39m2\u001b[39m\u001b[39m+\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maudio1\u001b[39m.\u001b[39mduration)])\n\u001b[1;32m     78\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvideo \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvideo\u001b[39m.\u001b[39mset_audio(audio_compo)\n\u001b[0;32m---> 79\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvideo \u001b[39m=\u001b[39m CompositeVideoClip(\n\u001b[1;32m     80\u001b[0m     [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvideo, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvideo\u001b[39m.\u001b[39;49mset_start(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvideo\u001b[39m.\u001b[39;49mduration)])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/moviepy/video/compositing/CompositeVideoClip.py:79\u001b[0m, in \u001b[0;36mCompositeVideoClip.__init__\u001b[0;34m(self, clips, size, bg_color, use_bgclip, ismask)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclips \u001b[39m=\u001b[39m clips\n\u001b[0;32m---> 79\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbg \u001b[39m=\u001b[39m ColorClip(size, color\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbg_color)\n\u001b[1;32m     80\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreated_bg \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[39m# compute duration\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/moviepy/video/VideoClip.py:1014\u001b[0m, in \u001b[0;36mColorClip.__init__\u001b[0;34m(self, size, color, ismask, duration, col)\u001b[0m\n\u001b[1;32m   1012\u001b[0m w, h \u001b[39m=\u001b[39m size\n\u001b[1;32m   1013\u001b[0m shape \u001b[39m=\u001b[39m (h, w) \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39misscalar(color) \u001b[39melse\u001b[39;00m (h, w, \u001b[39mlen\u001b[39m(color))\n\u001b[0;32m-> 1014\u001b[0m ImageClip\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, np\u001b[39m.\u001b[39;49mtile(color, w \u001b[39m*\u001b[39;49m h)\u001b[39m.\u001b[39mreshape(shape),\n\u001b[1;32m   1015\u001b[0m                    ismask\u001b[39m=\u001b[39mismask, duration\u001b[39m=\u001b[39mduration)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mtile\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/lib/shape_base.py:1258\u001b[0m, in \u001b[0;36mtile\u001b[0;34m(A, reps)\u001b[0m\n\u001b[1;32m   1256\u001b[0m     \u001b[39mfor\u001b[39;00m dim_in, nrep \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(c\u001b[39m.\u001b[39mshape, tup):\n\u001b[1;32m   1257\u001b[0m         \u001b[39mif\u001b[39;00m nrep \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m-> 1258\u001b[0m             c \u001b[39m=\u001b[39m c\u001b[39m.\u001b[39;49mreshape(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, n)\u001b[39m.\u001b[39;49mrepeat(nrep, \u001b[39m0\u001b[39;49m)\n\u001b[1;32m   1259\u001b[0m         n \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m=\u001b[39m dim_in\n\u001b[1;32m   1260\u001b[0m \u001b[39mreturn\u001b[39;00m c\u001b[39m.\u001b[39mreshape(shape_out)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from Sprechen import Sprechen\n",
    "\n",
    "Sprechen(data_path=\"../data/lektion2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > tts_models/fr/mai/tacotron2-DDC is already downloaded.\n",
      " > vocoder_models/universal/libri-tts/fullband-melgan is already downloaded.\n",
      " > Using model: Tacotron2\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:16000\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:True\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:50.0\n",
      " | > mel_fmax:7600.0\n",
      " | > pitch_fmin:0.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:/home/dekelshoot/.local/share/tts/tts_models--fr--mai--tacotron2-DDC/scale_stats.npy\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Model's reduction rate `r` is set to: 1\n",
      " > Vocoder Model: fullband_melgan\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:24000\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:0\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:True\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:50.0\n",
      " | > mel_fmax:7600.0\n",
      " | > pitch_fmin:0.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:/home/dekelshoot/.local/share/tts/vocoder_models--universal--libri-tts--fullband-melgan/scale_stats.npy\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Generator Model: fullband_melgan_generator\n",
      " > Discriminator Model: melgan_multiscale_discriminator\n",
      " > Text splitted to sentences.\n",
      "['Questions et réponses sur la famille']\n",
      "kɛstjɔ̃ e ʁepɔ̃s syʁ la famij\n",
      " [!] Character '̃' not found in the vocabulary. Discarding it.\n",
      " > interpolating tts model output.\n",
      " > before interpolation : (80, 110)\n",
      " > after interpolation : torch.Size([1, 80, 165])\n",
      " > Processing time: 6.973006725311279\n",
      " > Real-time factor: 2.094625030132556\n",
      " > tts_models/fr/css10/vits is already downloaded.\n",
      " > Using model: vits\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:0\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:None\n",
      " | > fft_size:1024\n",
      " | > power:None\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:None\n",
      " | > signal_norm:None\n",
      " | > symmetric_norm:None\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:None\n",
      " | > pitch_fmax:None\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > initialization of speaker-embedding layers.\n",
      " > initialization of language-embedding layers.\n",
      " > Text splitted to sentences.\n",
      "['Questions et réponses sur la famille']\n",
      " > Processing time: 2.396486759185791\n",
      " > Real-time factor: 0.8527390433779805\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../temp/test2.wav'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from TTS.api import TTS\n",
    "tts = TTS(\n",
    "            \"tts_models/fr/mai/tacotron2-DDC\", progress_bar=False, gpu=False)\n",
    "tts.tts_to_file(text=\"Questions et réponses sur la famille\",\n",
    "                             file_path=\"../temp/test1.wav\",\n",
    "                             speaker_wav=\"../temp/ElevenLabs_2024-04-10T00_47_41_Daniel.mp3\",\n",
    "                             )\n",
    "tts = TTS(\n",
    "            \"tts_models/fr/css10/vits\", progress_bar=False, gpu=False)\n",
    "tts.tts_to_file(text=\"Questions et réponses sur la famille\",\n",
    "                             file_path=\"../temp/test2.wav\",\n",
    "                             speaker_wav=\"../temp/ElevenLabs_2024-04-10T00_47_41_Daniel.mp3\",\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > tts_models/fr/css10/vits is already downloaded.\n",
      " > Using model: vits\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:0\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:None\n",
      " | > fft_size:1024\n",
      " | > power:None\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:None\n",
      " | > signal_norm:None\n",
      " | > symmetric_norm:None\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:None\n",
      " | > pitch_fmax:None\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > initialization of speaker-embedding layers.\n",
      " > initialization of language-embedding layers.\n",
      " > Text splitted to sentences.\n",
      "[\"ElevenLabs est une société de logiciels spécialisée dans le développement de logiciels de synthèse vocale et de synthèse vocale à sonorité naturelle, utilisant l'intelligence artificielle et l'apprentissage profond.\", 'Elle a été reconnue comme l’une des principales entreprises à l’origine du AI Spring en cours.']\n",
      "elle a été reconnue comme l’une des principales entreprises à l’origine du ai spring en cours.\n",
      " [!] Character '’' not found in the vocabulary. Discarding it.\n",
      " > Processing time: 14.870877027511597\n",
      " > Real-time factor: 0.9341748292250625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../temp/test2.wav'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tts = TTS(\n",
    "            \"tts_models/fr/css10/vits\", progress_bar=False, gpu=False)\n",
    "tts.tts_to_file(text=\"ElevenLabs est une société de logiciels spécialisée dans le développement de logiciels de synthèse vocale et de synthèse vocale à sonorité naturelle, utilisant l'intelligence artificielle et l'apprentissage profond. Elle a été reconnue comme l’une des principales entreprises à l’origine du AI Spring en cours.\",\n",
    "                             file_path=\"../temp/test2.wav\",\n",
    "                             speaker_wav=\"../temp/MAMANE_09_04_2024.mp3\",\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > tts_models/de/css10/vits-neon is already downloaded.\n",
      " > Using model: vits\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:0\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:None\n",
      " | > fft_size:1024\n",
      " | > power:None\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:None\n",
      " | > signal_norm:None\n",
      " | > symmetric_norm:None\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:None\n",
      " | > pitch_fmax:None\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > initialization of speaker-embedding layers.\n",
      " > initialization of language-embedding layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Text splitted to sentences.\n",
      "['Fragen und Antworten zur Familie.']\n",
      " > Processing time: 2.720651865005493\n",
      " > Real-time factor: 0.786202212510106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../temp/test4.wav'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from TTS.api import TTS\n",
    "\n",
    "tts = TTS(\n",
    "            \"tts_models/de/css10/vits-neon\", progress_bar=False, gpu=False)\n",
    "tts.tts_to_file(text=\"Fragen und Antworten zur Familie.\",\n",
    "                             file_path=\"../temp/test4.wav\",\n",
    "                             speaker_wav=\"../temp/ElevenLabs_2024-04-10T00_47_41_Daniel.mp3\",\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > tts_models/fr/css10/vits is already downloaded.\n",
      " > Using model: vits\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:0\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:None\n",
      " | > fft_size:1024\n",
      " | > power:None\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:None\n",
      " | > signal_norm:None\n",
      " | > symmetric_norm:None\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:None\n",
      " | > pitch_fmax:None\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > initialization of speaker-embedding layers.\n",
      " > initialization of language-embedding layers.\n",
      " > Text splitted to sentences.\n",
      "[\"ElevenLabs est une société de logiciels spécialisée dans le développement de logiciels de synthèse vocale et de synthèse vocale à sonorité naturelle, utilisant l'intelligence artificielle et l'apprentissage profond.\", 'Elle a été reconnue comme l’une des principales entreprises à l’origine du AI Spring en cours.']\n",
      "elle a été reconnue comme l’une des principales entreprises à l’origine du ai spring en cours.\n",
      " [!] Character '’' not found in the vocabulary. Discarding it.\n",
      " > Processing time: 20.133166790008545\n",
      " > Real-time factor: 1.2647470363059772\n",
      " > Downloading model to /home/dekelshoot/.local/share/tts/voice_conversion_models--multilingual--vctk--freevc24\n",
      " > Model's license - MIT\n",
      " > Check https://choosealicense.com/licenses/mit/ for more info.\n",
      " > Using model: freevc\n",
      " > Loading pretrained speaker encoder model ...\n",
      "Loaded the voice encoder model on cpu in 12.70 seconds.\n",
      " > Downloading WavLM model to /home/dekelshoot/.local/share/tts/wavlm/WavLM-Large.pt ...\n"
     ]
    }
   ],
   "source": [
    "from TTS.api import TTS\n",
    "tts = TTS(\n",
    "            \"tts_models/fr/css10/vits\", progress_bar=False, gpu=False)\n",
    "tts.tts_with_vc_to_file(text=\"ElevenLabs est une société de logiciels spécialisée dans le développement de logiciels de synthèse vocale et de synthèse vocale à sonorité naturelle, utilisant l'intelligence artificielle et l'apprentissage profond. Elle a été reconnue comme l’une des principales entreprises à l’origine du AI Spring en cours.\",\n",
    "                             file_path=\"../temp/test.wav\",\n",
    "                             speaker_wav=\"../temp/ElevenLabs_2024-04-10T00_47_41_Daniel.mp3\",\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classes.Clip import  Leaf_clip,Title_clip,Composition_clip\n",
    "from Audio import Audio\n",
    "import utils\n",
    "from random import choice\n",
    "\n",
    "audio = Audio()\n",
    "cmp = Composition_clip()\n",
    "\n",
    "## title_clip\n",
    "audio.generate_audio(text=\"Lektion 1: Meine Familie\",\n",
    "                     speaker=\"Ana Florence\", language=\"de\" ,file_path=\"../temp/audio.wav\")\n",
    "\n",
    "cl = Title_clip(bg=choice(utils.get_bg()), format=\"16:9\", title=\"Lektion 1 : Meine Familie\",\n",
    "               audio=\"../temp/audio.wav\",)\n",
    "cmp.add_clip(cl.video)\n",
    "\n",
    "#leaf_clip\n",
    "audio.generate_audio(text=\"Bonjour monsieur.\",\n",
    "                     speaker=\"Torcull Diarmuid\", file_path=\"../temp/audio1.wav\")\n",
    "\n",
    "audio.generate_audio(text=\"Hallo Herr\",\n",
    "                     speaker=\"Ana Florence\", language=\"de\" ,file_path=\"../temp/audio2.wav\")\n",
    "\n",
    "cl1 = Leaf_clip(bg=choice(utils.get_bg()), format=\"16:9\", text=\"Bonjour monsieur.\",\n",
    "               traduction=\"Hallo Herr.\", audio1=\"../temp/audio1.wav\", audio2=\"../temp/audio2.wav\")\n",
    "cmp.add_clip(cl1.video)\n",
    "\n",
    "# leaf_clip2\n",
    "audio.generate_audio(text=\"Quel âge a-t-il ?\",\n",
    "                     speaker=\"Torcull Diarmuid\", file_path=\"../temp/audio3.wav\")\n",
    "\n",
    "audio.generate_audio(text=\"Wie alt ist er? \",\n",
    "                     speaker=\"Ana Florence\", language=\"de\" ,file_path=\"../temp/audio4.wav\")\n",
    "\n",
    "cl2 = Leaf_clip(bg=choice(utils.get_bg()), format=\"16:9\", text=\"Quel âge a-t-il ?\",\n",
    "               traduction=\"Wie alt ist er? \", audio1=\"../temp/audio3.wav\", audio2=\"../temp/audio4.wav\")\n",
    "cmp.add_clip(cl2.video)\n",
    "cmp.save(\"final.mp4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classes.Clip import Clip, Title_clip\n",
    "from Audio import Audio\n",
    "\n",
    "audio = Audio()\n",
    "\n",
    "\n",
    "audio.generate_audio(text=\"Lektion 1: Meine Familie\",\n",
    "                     speaker=\"Ana Florence\", language=\"de\" ,file_path=\"../temp/audio.wav\")\n",
    "\n",
    "cl = Title_clip(bg=[0, 100, 80], format=\"16:9\", title=\"Lektion 1 : Meine Familie\",\n",
    "               audio=\"../temp/audio.wav\",)\n",
    "cl.save(filename=\"test.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classes.Clip import Clip, Leaf_clip\n",
    "cl = Leaf_clip(bg=[0, 100, 80], format=\"16:9\", text=\"Nous apprendrons les différentes \",\n",
    "               traduction=\"Exécutez la commande Suivante\", audio1=\"../temp/audio3.wav\", audio2=\"../temp/audio2.wav\")\n",
    "cl.save(filename=\"test.mp4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import *\n",
    "TextClip.list('font')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'data': {1: {'text': 'Bonjour', 'traduction': 'Good Morning!!!'}, 2: {'text': 'Comment tu vas?', 'traduction': 'How are you?'}, 3: {'text': 'je vais bien merci', 'traduction': '\"I\\'m doing well'}}, 'title': 'dire bonjour'}\n",
    "for key in data[\"data\"].keys():\n",
    "    print(data[\"data\"][key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "from random import choice\n",
    "choice(utils.get_bg())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import time\n",
    "\n",
    "a=0\n",
    "b = 10\n",
    "\n",
    "for x in range(10):\n",
    "    c = (\"\\033[92m\"+str(a)+\"% [\"+a*\"#\"+b*\"-\"+\"]\"+\"\\033[0m\")\n",
    "    sys.stdout.write('\\r'+c)\n",
    "    time.sleep(0.5)\n",
    "    a+=1\n",
    "    b-=1\n",
    "print(\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import curses, time, os\n",
    "from time import sleep\n",
    "def sp(str):\n",
    "  for letter in str:\n",
    "    sys.stdout.write(letter)\n",
    "    sys.stdout.flush()\n",
    "    time.sleep(0.09)\n",
    "    \n",
    "  print()\n",
    "# to use it:\n",
    "sp(\"▁ ▂ ▃ ▄ ▅ ▆ ▇ █ ▇ ▆ ▅ ▄ ▃ ▁\")\n",
    "# this will output each of those different cacracters one by one\n",
    "# thus making a loading animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > tts_models/de/css10/vits-neon is already downloaded.\n",
      " > Using model: vits\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:0\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:None\n",
      " | > fft_size:1024\n",
      " | > power:None\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:None\n",
      " | > signal_norm:None\n",
      " | > symmetric_norm:None\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:None\n",
      " | > pitch_fmax:None\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > initialization of speaker-embedding layers.\n",
      " > initialization of language-embedding layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting voice ...\n",
      "['Pour concevoir un logiciel, vous devez connaître les objectifs qu’il doit atteindre.']\n",
      "pour concevoir un logiciel, vous devez connaître les objectifs qu’il doit atteindre.\n",
      " [!] Character '’' not found in the vocabulary. Discarding it.\n",
      " > Processing time: 15.531862258911133\n",
      " > Real-time factor: 2.200107685842523\n",
      "voice genered ...\n",
      "playing audio ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<moviepy.audio.io.AudioFileClip.AudioFileClip at 0x7fbc0c007250>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Audio import Audio_fr , Audio_de\n",
    "audio = Audio_de()\n",
    "audio.generate_audio(text=\"Pour concevoir un logiciel, vous devez connaître les objectifs qu’il doit atteindre.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
